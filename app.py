import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import mysql.connector
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.sentiment import SentimentIntensityAnalyzer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import nltk
from datetime import datetime

# Configuraci√≥ inicial de NLTK
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
    nltk.download('vader_lexicon', quiet=True)

# Configuraci√≥ de stopwords
stop_words_cat = {'que', 'qu√®', 'com', 'quin', 'quina', 'quins', 'quines', 'per', 'els', 'les',
                 'un', 'una', 'uns', 'unes', 'el', 'la', 'els', 'les', 'i', 'o', 'per√≤', 'perqu√®',
                 'si', 'no', 'hi', 'ha', 't√©', 'tenen', 'tenim', 'est√†', 'estan', 'estem',
                 'aquest', 'aquesta', 'aquests', 'aquestes', 'aquell', 'aquella', 'aquells', 'aquelles','va','van','dels','amb','m√©s','mes','√©s','s√≥n','eren'}

# Configuraci√≥ de la p√†gina
st.set_page_config(page_title="An√†lisi de Parlant Amb...", layout="wide")

# T√≠tol principal
st.title("üìä Dashboard d'An√†lisi de Parlant Amb...")

# Configuraci√≥ de la base de dades
DB_CONFIG =  st.secrets["DB_CONFIG"]

# Connexi√≥ a la base de dades
@st.cache_resource
def get_database_connection():
    try:
        return mysql.connector.connect(**DB_CONFIG)
    except mysql.connector.Error as err:
        st.error(f"Error de connexi√≥ a la base de dades: {err}")
        return None

# Funci√≥ per carregar les dades
@st.cache_data
def load_data():
    conn = get_database_connection()
    if conn is None:
        st.stop()

    try:
        query = """
        SELECT id, pregunta, resposta, infografia, data, tema, idc, curso,topico
        FROM teclaPREGUNTES
        """
        df = pd.read_sql(query, conn)
        return df
    except Exception as e:
        st.error(f"Error en carregar les dades: {str(e)}")
        return None
    finally:
        conn.close()

# Carregar dades
df = load_data()
if df is None:
    st.stop()

# Sidebar amb filtres
st.sidebar.title("Filtres")
selected_curso = st.sidebar.multiselect(
    "Filtra per curs:",
    options=sorted(df['curso'].unique()),
    default=sorted(df['curso'].unique())
)

selected_tema = st.sidebar.multiselect(
    "Filtra per tema:",
    options=sorted(df['topico'].unique()),
    default=sorted(df['topico'].unique())
)

# Aplicar filtres
filtered_df = df[
    (df['curso'].isin(selected_curso)) &
    (df['topico'].isin(selected_tema))
]

# Pestanyes principals
tab1, tab2, tab3 = st.tabs(["üìà An√†lisi Descriptiva", "üìù An√†lisi de Text", "üë• An√†lisi d'Usuaris"])

with tab1:
    st.header("An√†lisi Descriptiva")

    # Estad√≠stiques b√†siques
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Usuaris √önics", len(filtered_df['idc'].unique()))

    with col2:
        avg_interactions = filtered_df.groupby('idc').size().mean()
        st.metric("Mitjana d'interaccions per usuari", f"{avg_interactions:.2f}")

    with col3:
        total_topics = len(filtered_df['topico'].unique())
        st.metric("Total de Temes", total_topics)

    with col4:
        images = filtered_df['infografia'].notna().sum()
        st.metric("Total d'Infografies", images)

    # Gr√†fics
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Distribuci√≥ de Temes")
        topic_dist = filtered_df['topico'].value_counts()
        fig = px.pie(
            values=topic_dist.values,
            names=topic_dist.index,
            title="Distribuci√≥ de Temes"
        )
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.subheader("Distribuci√≥ per Curs")
        curso_dist = filtered_df['curso'].value_counts()
        fig = px.bar(
            x=curso_dist.index,
            y=curso_dist.values,
            title="Distribuci√≥ per Curs"
        )
        st.plotly_chart(fig, use_container_width=True)

    # Activitat temporal
    st.subheader("Activitat al llarg del temps")
    filtered_df['data'] = pd.to_datetime(filtered_df['data'])
    daily_activity = filtered_df.resample('D', on='data').size()
    fig = px.line(
        x=daily_activity.index,
        y=daily_activity.values,
        title="Activitat Di√†ria",
        labels={'x': 'Data', 'y': 'Nombre d\'interaccions'}
    )
    st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.header("An√†lisi de Text")

    # Preparar stopwords
    try:
        stop_words = set(stopwords.words('spanish') + stopwords.words('english'))
        stop_words.update(stop_words_cat)
    except Exception as e:
        stop_words = stop_words_cat
        st.warning("S'han carregat nom√©s les stopwords en catal√†")

    # An√†lisi de freq√º√®ncia de paraules
    st.subheader("Paraules m√©s Freq√ºents en Preguntes")

    def get_word_freq(texts):
        words = []
        for text in texts:
            if isinstance(text, str):
                try:
                    tokens = word_tokenize(text.lower())
                    words.extend([w for w in tokens if w.isalnum() and w not in stop_words and len(w) > 1])
                except Exception as e:
                    continue
        return pd.Series(words).value_counts()

    word_freq = get_word_freq(filtered_df['pregunta'])

    # Mostrar n√∫vol de paraules
    if not word_freq.empty:
        try:
            wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=100).generate_from_frequencies(word_freq)
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)
        except Exception as e:
            st.error(f"Error en generar el n√∫vol de paraules: {str(e)}")

        # Mostrar les 20 paraules m√©s freq√ºents
        st.subheader("Top 20 Paraules m√©s Freq√ºents")
        fig = px.bar(
            x=word_freq.head(20).index,
            y=word_freq.head(20).values,
            title="Paraules m√©s Freq√ºents en Preguntes"
        )
        st.plotly_chart(fig, use_container_width=True)

    # An√†lisi de paraules per tema
    st.subheader("An√†lisi de Paraules per Tema")

    # Selector de tema
    selected_topic = st.selectbox(
        "Selecciona un tema per veure les seves paraules m√©s freq√ºents:",
        options=sorted(filtered_df['topico'].unique())
    )

    # Filtrar preguntes pel tema seleccionat
    topic_questions = filtered_df[filtered_df['topico'] == selected_topic]['pregunta']
    topic_word_freq = get_word_freq(topic_questions)

    if not topic_word_freq.empty:
        col1, col2 = st.columns(2)

        with col1:
            try:
                # N√∫vol de paraules pel tema
                wordcloud_topic = WordCloud(width=400, height=300, background_color='white', max_words=50).generate_from_frequencies(topic_word_freq)
                fig, ax = plt.subplots(figsize=(8, 6))
                ax.imshow(wordcloud_topic, interpolation='bilinear')
                ax.axis('off')
                plt.title(f"N√∫vol de paraules - {selected_topic}")
                st.pyplot(fig)
            except Exception as e:
                st.error(f"Error en generar el n√∫vol de paraules pel tema: {str(e)}")

        with col2:
            # Top 15 paraules m√©s freq√ºents pel tema
            fig = px.bar(
                x=topic_word_freq.head(15).index,
                y=topic_word_freq.head(15).values,
                title=f"Top 15 Paraules m√©s Freq√ºents - {selected_topic}"
            )
            st.plotly_chart(fig, use_container_width=True)

        # Estad√≠stiques del tema
        total_questions = len(topic_questions)
        avg_words = topic_questions.str.split().str.len().mean()

        col1, col2 = st.columns(2)
        with col1:
            st.metric("Total de preguntes", total_questions)
        with col2:
            st.metric("Mitjana de paraules per pregunta", f"{avg_words:.1f}")

    # Topic Modeling
    st.subheader("Descobriment de Temes")
    n_topics = st.slider("Nombre de temes a descobrir", min_value=2, max_value=10, value=5)

    try:
        vectorizer = CountVectorizer(max_features=1000, stop_words=list(stop_words))
        doc_term_matrix = vectorizer.fit_transform(filtered_df['pregunta'].fillna(''))

        lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)
        lda_output = lda.fit_transform(doc_term_matrix)

        # Mostrar els temes descoberts
        feature_names = vectorizer.get_feature_names_out()
        for topic_idx, topic in enumerate(lda.components_):
            top_words = [feature_names[i] for i in topic.argsort()[:-10-1:-1]]
            st.write(f"Tema {topic_idx + 1}: {', '.join(top_words)}")
    except Exception as e:
        st.error(f"Error en el descobriment de temes: {str(e)}")

with tab3:
    st.header("An√†lisi de Comportament d'Usuaris")

    # Segmentaci√≥ d'usuaris per freq√º√®ncia d'√∫s
    user_activity = filtered_df.groupby('idc').size()

    def get_user_segment(interactions):
        if interactions <= 2:
            return "Poc actiu"
        elif interactions <= 5:
            return "Moderadament actiu"
        else:
            return "Molt actiu"

    user_segments = user_activity.apply(get_user_segment)
    segment_dist = user_segments.value_counts()

    st.subheader("Segmentaci√≥ d'Usuaris")
    fig = px.pie(
        values=segment_dist.values,
        names=segment_dist.index,
        title="Distribuci√≥ de Segments d'Usuaris"
    )
    st.plotly_chart(fig, use_container_width=True)

    # An√†lisi de retenci√≥
    st.subheader("An√†lisi de Retenci√≥")

    user_first_interaction = filtered_df.groupby('idc')['data'].min()
    user_last_interaction = filtered_df.groupby('idc')['data'].max()

    retention_days = (user_last_interaction - user_first_interaction).dt.days

    fig = px.histogram(
        x=retention_days.values,
        nbins=30,
        title="Distribuci√≥ del Temps de Retenci√≥ (dies)",
        labels={'x': 'Dies entre primera i √∫ltima interacci√≥', 'y': 'Nombre d\'usuaris'}
    )
    st.plotly_chart(fig, use_container_width=True)

    # Estad√≠stiques de retenci√≥
    st.write(f"Mitjana de dies de retenci√≥: {retention_days.mean():.1f} dies")
    st.write(f"Mediana de dies de retenci√≥: {retention_days.median():.1f} dies")
